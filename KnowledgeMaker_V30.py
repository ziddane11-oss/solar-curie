import os
import sys
import json
import requests
import threading
import textwrap
import shutil
import re
import random
import time
import numpy as np
from datetime import datetime
from PIL import Image, ImageDraw, ImageFont
import customtkinter as ctk
from tkinter import messagebox, filedialog
from moviepy.editor import *
import moviepy.audio.fx.all as afx
from proglog import ProgressBarLogger # ì§„í–‰ë¥  ì—°ë™ìš©

# AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
try:
    from google import genai
    from google.genai import types
except ImportError:
    pass

try:
    from openai import OpenAI
except ImportError:
    pass


# ==========================================
# 1. ì„¤ì • ë° ë¦¬ì†ŒìŠ¤
# ==========================================
ctk.set_appearance_mode("Dark")
ctk.set_default_color_theme("dark-blue")

# ğŸ¨ [ë„¤ì˜¨-ë¯¸ë‹ˆë©€ í…Œë§ˆ] ì´ŒìŠ¤ëŸ½ì§€ ì•Šì€ ê³ ê¸‰ ë„¤ì˜¨
BG = "#0B0F14"
CARD = "#121826"
CARD2 = "#0F1724"
TEXT = "#B8C4D6"
MUTED = "#7A869A"
NEON = "#00E5FF"
NEON2 = "#7C5CFF"
BORDER = "#1F2A3A"
SUCCESS = "#2CC985"
DANGER = "#FF3B5C"

# í°íŠ¸ (Malgun Gothic í†µì¼)
TITLE_FONT = ("Malgun Gothic", 26, "bold")
H2_FONT = ("Malgun Gothic", 15, "bold")
BODY_FONT = ("Malgun Gothic", 13)
SMALL_FONT = ("Malgun Gothic", 12)
FONT_BOLD = ("Malgun Gothic", 16, "bold")
FONT_NORMAL = ("Malgun Gothic", 14)
FONT_SMALL = ("Malgun Gothic", 12)
R = 20  # corner_radius

FONT_PATH = "C:/Windows/Fonts/malgunbd.ttf"
if not os.path.exists(FONT_PATH):
    FONT_PATH = "C:/Windows/Fonts/malgun.ttf"
if not os.path.exists(FONT_PATH):
    FONT_PATH = "C:/Windows/Fonts/gulim.ttc"

CONFIG_FILE = "config_ultra.json"

VOICE_OPTIONS = {
    "ì°¨ë¶„í•œ ë‚¨ì„± (Antoni)": "ErXwobaYiN019PkySvjV",
    "ë°ì€ ì—¬ì„± (Rachel)": "21m00Tcm4TlvDq8ikWAM",
    "êµµì€ ë‚¨ì„± (Clyde)": "2EiwWnXFnvU5JabPnv8n",
    "í• ë¨¸ë‹ˆ (Mimi)": "zrHiDhphv9ZnVXBqCLjz"
}

COLOR_OPTIONS = {
    "í™©ê¸ˆìƒ‰ (ê¸°ë³¸)": "#FFD700",
    "ê¹”ë”í•œ í°ìƒ‰": "#FFFFFF",
    "ë„¤ì˜¨ ë¯¼íŠ¸": "#00FFC8",
    "ê°•ë ¬í•œ ë ˆë“œ": "#FF0000"
}

LANG_OPTIONS = ["Korean", "English", "Japanese", "Spanish"]

def load_config():
    default = {"openai_key": "", "eleven_key": "", "google_key": ""}
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r") as f: return {**default, **json.load(f)}
        except: pass
    return default

def save_config(openai, eleven, google):
    with open(CONFIG_FILE, "w") as f:
        json.dump({"openai_key": openai, "eleven_key": eleven, "google_key": google}, f)

# ==========================================
# 2. ë¡œì§ í•¨ìˆ˜ë“¤
# ==========================================
# [ìˆ˜ì •] ì§„í–‰ë¥  ë¡œê±°: ìˆ«ìê°€ 'ë°”ë€” ë•Œë§Œ' GUI ì—…ë°ì´íŠ¸ (ë ‰ ë°©ì§€)
class TkLogger(ProgressBarLogger):
    def __init__(self, callback):
        super().__init__()
        self.callback = callback
        self.last_percentage = -1 # ë§ˆì§€ë§‰ìœ¼ë¡œ ë³´ê³ í•œ í¼ì„¼íŠ¸

    def bars_callback(self, bar, attr, value, old_value=None):
        if bar == 't':
            if self.bars[bar]['total'] > 0:
                percentage = int((value / self.bars[bar]['total']) * 100)
                # ğŸ”¥ [í•µì‹¬] 1%ë¼ë„ ë³€í–ˆì„ ë•Œë§Œ ì—…ë°ì´íŠ¸ (GUI ë¶€í•˜ 99% ê°ì†Œ)
                if percentage != self.last_percentage:
                    self.callback(percentage)
                    self.last_percentage = percentage

def retry_on_429(func, max_retries=3, initial_wait=60):
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            error_str = str(e)
            if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                if attempt < max_retries - 1:
                    wait_time = initial_wait * (2 ** attempt)
                    print(f"â³ API ì œí•œ ê°ì§€. {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt+1}/{max_retries})...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise Exception(f"API í• ë‹¹ëŸ‰ ì´ˆê³¼. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            else:
                raise e
    raise Exception("ì¬ì‹œë„ ì‹¤íŒ¨")

# ğŸ”¥ [ì‹ ê·œ] ì´ëª¨ì§€/íŠ¹ìˆ˜ë¬¸ì ì œê±° í•¨ìˆ˜
def strip_emojis(text):
    if not text:
        return text
    # ì´ëª¨ì§€/í”½í† ê·¸ë¨/ë³€í˜• ì„ íƒì/ZWJ ì œê±°
    emoji_pattern = re.compile(
        "[" 
        "\U0001F1E0-\U0001F1FF"  # flags
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F680-\U0001F6FF"  # transport & map
        "\U0001F700-\U0001F77F"  # alchemical
        "\U0001F780-\U0001F7FF"  # geometric
        "\U0001F800-\U0001F8FF"  # arrows
        "\U0001F900-\U0001F9FF"  # supplemental symbols
        "\U0001FA00-\U0001FAFF"  # extended symbols
        "\u2600-\u27BF"          # misc symbols
        "\uFE0F"                 # variation selector-16
        "\u200D"                 # zero width joiner
        "]+",
        flags=re.UNICODE
    )
    text = emoji_pattern.sub("", text)
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

def generate_viral_content(api_key, topic, language):
    print(f"[Gemini] ê¸°íšì•ˆ + SEO ë°ì´í„° ìƒì„± ì¤‘ ({language})...")
    client = genai.Client(api_key=api_key)
    
    system_prompt = f"""
    You are a viral YouTube Shorts expert. 
    Topic: {topic}. Target Language: **{language}**.
    
    1. Create a "Hook Title" (3-5 words, clickbait).
    2. Create a script (Casual tone, 40-50 secs).
    3. Create 6 Image Prompts (English only, cinematic style).
    4. **Create YouTube Metadata (SEO):** 3 Titles, Description, 15 Hashtags.
    
    - DO NOT use emojis, emoticons, or decorative symbols.
    - Use plain text only. No special characters except basic punctuation.
    
    Output Format (Strictly):
    [Hook]... [Script]... [Prompts]... [Metadata]...
    """
    
    def _generate():
        response = client.models.generate_content(model='gemini-2.0-flash', contents=system_prompt)
        text = strip_emojis(response.text)  # ğŸ”¥ ì´ëª¨ì§€ ì œê±° í›„ì²˜ë¦¬
        hook = "Watch This!"; script = ""; prompts = ["Abstract background"]; metadata = "SEO Data Not Generated."

        if "[Hook]" in text:
            parts = text.split("[Hook]")[1].split("[Script]")
            hook = strip_emojis(parts[0].strip())
            if len(parts) > 1:
                script_parts = parts[1].split("[Prompts]")
                script = script_parts[0].strip()
                # ê´„í˜¸ ì•ˆì˜ ì„¤ëª… ì œê±°
                script = re.sub(r'\([^)]*\)', '', script)
                script = re.sub(r'\[[^\]]*\]', '', script)
                script = re.sub(r'\s+', ' ', script).strip()
                script = strip_emojis(script)  # ğŸ”¥ ì´ëª¨ì§€ ì œê±°
                if len(script_parts) > 1:
                    prompt_parts = script_parts[1].split("[Metadata]")
                    prompts = [p.strip() for p in prompt_parts[0].split('\n') if p.strip()]
                    if len(prompt_parts) > 1:
                        metadata = strip_emojis(prompt_parts[1].strip())  # ğŸ”¥ ì´ëª¨ì§€ ì œê±°
        return hook, script, prompts, metadata
    
    try:
        return retry_on_429(_generate)
    except Exception as e:
        raise Exception(f"AI ìƒì„± ì‹¤íŒ¨: {e}")

def generate_voice(api_key, text, out_path, voice_id):
    print(f"ğŸ™ï¸ [ElevenLabs] ìŒì„± ìƒì„± ì¤‘...")
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    headers = {"xi-api-key": api_key, "Content-Type": "application/json"}
    data = {"text": text, "model_id": "eleven_multilingual_v2"} 
    res = requests.post(url, json=data, headers=headers)
    if res.status_code == 200:
        with open(out_path, "wb") as f: f.write(res.content)
        return True
    return False

def generate_images(api_key, prompts):
    print("ğŸ¨ [OpenAI DALL-E] ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
    client = OpenAI(api_key=api_key)
    paths = []
    if os.path.exists("images_ultra"): shutil.rmtree("images_ultra")
    os.makedirs("images_ultra")
    
    MAX_IMAGES = 6  # âœ… 6ì¥ìœ¼ë¡œ ì¦ê°€
    if not prompts: prompts = ["Abstract background"]
    prompts = prompts[:MAX_IMAGES]
    
    for i, p in enumerate(prompts):
        path = f"images_ultra/scene_{i}.png"
        clean_p = re.sub(r'^\d+[\.\)]\s*', '', p)
        try:
            print(f"   â””â”€ ì´ë¯¸ì§€ {i+1} ìƒì„± ìš”ì²­...")
            response = client.images.generate(
                model="dall-e-3", prompt=f"high quality, cinematic, vertical composition, {clean_p}",
                size="1024x1792", quality="standard", n=1
            )
            image_url = response.data[0].url
            img_data = requests.get(image_url).content
            with open(path, 'wb') as f: f.write(img_data)
            paths.append(path)
            print(f"   âœ… ì´ë¯¸ì§€ {i+1} ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ ì´ë¯¸ì§€ {i+1} ì‹¤íŒ¨, ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©: {e}")
            img = Image.new('RGB', (1024, 1792), '#1a1a2e')
            d = ImageDraw.Draw(img)
            d.text((450, 900), f"Scene {i+1}", fill='#888888')
            img.save(path); paths.append(path)
    return paths

def create_hook_clip(text, duration=3.0):
    w, h = 1080, 1920
    img = Image.new('RGB', (w, h), (20, 20, 20))
    draw = ImageDraw.Draw(img)
    try: font = ImageFont.truetype(FONT_PATH, 110)
    except: font = ImageFont.load_default()
    lines = textwrap.wrap(text, width=10); total_h = len(lines) * 130; y = (h - total_h) // 2
    for line in lines:
        bbox = draw.textbbox((0,0), line, font=font); x = (w - (bbox[2]-bbox[0])) // 2
        draw.text((x+5, y+5), line, font=font, fill="black")
        draw.text((x, y), line, font=font, fill="#FF0055")
        y += 130
    return ImageClip(np.array(img)).set_duration(duration)

def create_caption_clip(text, duration, text_color):
    """ìë§‰ í´ë¦½ ìƒì„± - RGBA íˆ¬ëª… ë°°ê²½ + mask ë°©ì‹ (ì´ë¯¸ì§€ê°€ ë³´ì´ë„ë¡)"""
    w, h = 1080, 1920
    
    # ë¹ˆ í…ìŠ¤íŠ¸ë©´ ì™„ì „ íˆ¬ëª… í´ë¦½ ë°˜í™˜
    if not text.strip():
        transparent = np.zeros((h, w, 3), dtype=np.uint8)
        mask_arr = np.zeros((h, w), dtype=np.float64)
        clip = ImageClip(transparent).set_duration(duration)
        mask = ImageClip(mask_arr, ismask=True).set_duration(duration)
        return clip.set_mask(mask).set_position("center")
    
    # ğŸ”¥ [í•µì‹¬] RGBA íˆ¬ëª… ë°°ê²½ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±
    img = Image.new('RGBA', (w, h), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    try:
        font = ImageFont.truetype(FONT_PATH, 70)
    except:
        font = ImageFont.load_default()
    
    lines = textwrap.wrap(text, width=14)
    y = int(h * 0.75) - ((len(lines) * 85) // 2)
    
    for line in lines:
        bbox = draw.textbbox((0, 0), line, font=font)
        x = (w - (bbox[2] - bbox[0])) // 2
        # ê·¸ë¦¼ì (ë¶ˆíˆ¬ëª…)
        draw.text((x + 5, y + 5), line, font=font, fill=(30, 30, 30, 255))
        # ë³¸ë¬¸ (ë¶ˆíˆ¬ëª…)
        from PIL import ImageColor
        try:
            r, g, b = ImageColor.getrgb(text_color)
        except:
            r, g, b = 255, 215, 0  # ê¸°ë³¸ í™©ê¸ˆìƒ‰
        draw.text((x, y), line, font=font, fill=(r, g, b, 255))
        y += 85
    
    # RGBAë¥¼ RGB + Alpha maskë¡œ ë¶„ë¦¬
    arr = np.array(img)
    rgb = arr[:, :, :3]
    alpha = arr[:, :, 3] / 255.0  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
    
    clip = ImageClip(rgb).set_duration(duration)
    mask = ImageClip(alpha, ismask=True).set_duration(duration)
    return clip.set_mask(mask).set_position("center")

# [ìµœì¢… ìˆ˜ì •] make_video í•¨ìˆ˜: íš¨ê³¼ ì œê±° + Pillow ê°•ì œ ë¦¬ì‚¬ì´ì§• (ë¸”ë™ìŠ¤í¬ë¦° í•´ê²°ìš©)
def make_video(voice_path, bgm_path, img_paths, script, hook_title, out_name, text_color, use_hook, progress_callback=None):
    print("ğŸ¬ ì˜ìƒ ì¡°ë¦½ ë° ë Œë”ë§ ì¤€ë¹„...")
    
    # 1. ì˜¤ë””ì˜¤ ì„¤ì •
    voice = AudioFileClip(voice_path)
    total_dur = voice.duration + 1.0
    
    final_audio = voice
    if bgm_path and os.path.exists(bgm_path):
        bgm = AudioFileClip(bgm_path)
        full_len = total_dur + (3.0 if use_hook else 0)
        bgm = afx.audio_loop(bgm, duration=full_len).volumex(0.12)
        final_audio = bgm 

    # 2. ì´ë¯¸ì§€ ê°œìˆ˜ ê³„ì‚° (2ì´ˆ ì»· ê¸°ì¤€ - ë” ì—­ë™ì )
    CUT_SEC = 2.0
    if not img_paths: return
    req_imgs = max(len(img_paths), int(total_dur / CUT_SEC))
    if len(img_paths) < req_imgs: img_paths = img_paths * (req_imgs//len(img_paths)+1)
    img_paths = img_paths[:req_imgs]

    # 3. ìë§‰ ë¶„í•  (í•œêµ­ì–´ í˜¸í™˜ - ê¸¸ì´ ê¸°ë°˜ ê· ë“± ë¶„í• )
    n = len(img_paths)
    script_clean = re.sub(r'\s+', ' ', script).strip()
    
    if n <= 1 or not script_clean:
        chunks = [script_clean] if script_clean else [""]
    else:
        # ê¸¸ì´ ê¸°ë°˜ ê· ë“± ë¶„í• 
        size = max(1, len(script_clean) // n)
        chunks = []
        for i in range(0, len(script_clean), size):
            chunk = script_clean[i:i+size].strip()
            if chunk:
                chunks.append(chunk)
        # ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì²­í¬ ë°˜ë³µ
        while len(chunks) < n:
            chunks.append(chunks[-1] if chunks else "")
        chunks = chunks[:n]

    clip_dur = total_dur / n
    main_clips = []
    
    # ğŸ”¥ [ì—­ë™ì  íš¨ê³¼] ì„¤ì •
    TRANSITION = 0.20   # ë¹ ë¥¸ ì „í™˜
    SCALE = 1.18        # í™•ëŒ€ (íŒ¬ íš¨ê³¼ìš©)
    FLASH_DUR = 0.06    # ì»· ì‹œì‘ ë²ˆì©
    FLASH_OPA = 0.20    # í”Œë˜ì‹œ íˆ¬ëª…ë„
    ROTATE_DEG = 1.2    # ë¯¸ì„¸ íšŒì „
    
    print("   â””â”€ ì´ë¯¸ì§€ í´ë¦½ ìƒì„± ì¤‘ (ì—­ë™ì  ì¹´ë©”ë¼ ë¬´ë¹™ ì ìš©)...")
    for i, (p, txt) in enumerate(zip(img_paths, chunks)):
        try:
            # 1. PILë¡œ ì•ˆì „í•˜ê²Œ ì´ë¯¸ì§€ ë¡œë“œ
            pil_img = Image.open(p).convert('RGB')
            img_array = np.array(pil_img)
            
            # 2. ì´ë¯¸ì§€ í´ë¦½ ìƒì„± + í™•ëŒ€
            img = ImageClip(img_array).set_duration(clip_dur)
            img = img.resize(newsize=(1080, 1920)).resize(SCALE)
            
            # 3. ğŸ”¥ íŒ¬ íš¨ê³¼ (ìœ„ì¹˜ë§Œ ì´ë™ - ì•ˆì •ì )
            dx = img.w - 1080
            dy = img.h - 1920
            
            # 4ë°©í–¥ íŒ¨í„´: ì¢Œâ†’ìš°, ìš°â†’ì¢Œ, ìƒâ†’í•˜, í•˜â†’ìƒ
            patterns = [
                ((0, dy/2), (dx, dy/2)),       # left -> right
                ((dx, dy/2), (0, dy/2)),       # right -> left
                ((dx/2, 0), (dx/2, dy)),       # top -> bottom
                ((dx/2, dy), (dx/2, 0)),       # bottom -> top
            ]
            (sx, sy), (ex, ey) = patterns[i % len(patterns)]
            
            def pos(t, sx=sx, sy=sy, ex=ex, ey=ey, dur=clip_dur):
                p = t / dur if dur > 0 else 0
                x = sx + (ex - sx) * p
                y = sy + (ey - sy) * p
                return (-x, -y)
            
            img = img.set_position(pos)
            
            # 4. ğŸ”¥ ê°€ë” ë¯¸ì„¸ íšŒì „
            if i % 3 == 0:
                img = img.rotate(ROTATE_DEG)
            elif i % 3 == 1:
                img = img.rotate(-ROTATE_DEG)
            
            # 5. ìë§‰ ìƒì„±
            sub = create_caption_clip(txt, clip_dur, text_color)
            
            # 6. í•©ì²´
            combined = CompositeVideoClip([img, sub], size=(1080, 1920))
            
            # 7. ğŸ”¥ ì»· ì‹œì‘ í”Œë˜ì‹œ (ë²ˆì©)
            from moviepy.video.VideoClip import ColorClip
            flash = ColorClip(size=(1080, 1920), color=(255, 255, 255)).set_duration(FLASH_DUR).set_opacity(FLASH_OPA)
            combined = CompositeVideoClip([combined, flash.set_start(0)], size=(1080, 1920))
            
            # 8. í¬ë¡œìŠ¤í˜ì´ë“œ íš¨ê³¼
            combined = combined.fadein(TRANSITION).fadeout(TRANSITION)
            
            main_clips.append(combined)
            
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ (Scene {i}): {e}")
            continue

    if not main_clips: 
        print("âŒ ìƒì„±ëœ í´ë¦½ ì—†ìŒ"); return
        
    # ğŸ”¥ í¬ë¡œìŠ¤í˜ì´ë“œë¡œ ì´ì–´ë¶™ì´ê¸° (ê²¹ì¹˜ë©´ì„œ ì „í™˜)
    final_main_clip = concatenate_videoclips(main_clips, method="compose", padding=-TRANSITION)
    
    # ì˜¤ë””ì˜¤ ë° í›„í‚¹ ë¡œì§ (ê¸°ì¡´ ìœ ì§€)
    if bgm_path and os.path.exists(bgm_path): pass 
    else: final_audio = voice

    if use_hook and hook_title:
        hook_clip = create_hook_clip(hook_title, duration=3.0)
        final_video = concatenate_videoclips([hook_clip, final_main_clip])
        
        if bgm_path and os.path.exists(bgm_path):
            bgm_clip = AudioFileClip(bgm_path)
            bgm_clip = afx.audio_loop(bgm_clip, duration=final_video.duration).volumex(0.12)
            voice = voice.set_start(3.0)
            final_video = final_video.set_audio(CompositeAudioClip([bgm_clip, voice]))
        else:
            voice = voice.set_start(3.0)
            final_video = final_video.set_audio(voice)
    else:
        final_video = final_main_clip
        if bgm_path and os.path.exists(bgm_path):
            bgm_clip = AudioFileClip(bgm_path)
            bgm_clip = afx.audio_loop(bgm_clip, duration=final_main_clip.duration).volumex(0.12)
            final_video = final_video.set_audio(CompositeAudioClip([voice, bgm_clip]))
        else:
            final_video = final_video.set_audio(voice)

    print("ğŸ¬ ë Œë”ë§ ì‹œì‘ (ì•ˆì „ ëª¨ë“œ)...")
    final_video.write_videofile(
        out_name, 
        fps=24, 
        codec='libx264', 
        audio_codec='aac', 
        preset='medium',
        threads=4
    )
    return out_name

# ==========================================
# 3. GUI (ULTRA - Console Embedded)
# ==========================================
class KnowledgeMakerUltra(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Knowledge Maker V30")
        self.geometry("700x850")
        self.configure(fg_color=BG)
        cfg = load_config()
        self.selected_bgm = None
        self.gen_data = {} 

        # ë©”ì¸ ì»¨í…Œì´ë„ˆ (ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
        self.main_scroll = ctk.CTkScrollableFrame(self, fg_color=BG)
        self.main_scroll.pack(fill="both", expand=True)

        # 1. í—¤ë” (ë„¤ì˜¨-ë¯¸ë‹ˆë©€)
        header = ctk.CTkFrame(self.main_scroll, fg_color="transparent")
        header.pack(fill="x", padx=20, pady=(20, 10))
        ctk.CTkLabel(header, text="Knowledge Maker", font=TITLE_FONT, text_color=TEXT).pack(side="left")
        ctk.CTkLabel(header, text="v3.0", font=SMALL_FONT, text_color=NEON).pack(side="left", padx=10)

        # 2. API ì¹´ë“œ
        f_conf = ctk.CTkFrame(self.main_scroll, fg_color=CARD, corner_radius=R, border_width=1, border_color=BORDER)
        f_conf.pack(fill="x", padx=20, pady=10)
        ctk.CTkLabel(f_conf, text="API ì„¤ì •", font=H2_FONT, text_color=NEON).pack(anchor="w", padx=20, pady=10)
        
        self.entries = {}
        gf = ctk.CTkFrame(f_conf, fg_color="transparent")
        gf.pack(fill="x", padx=10, pady=(0, 10))
        gf.columnconfigure(1, weight=1)
        
        for r, (lbl, key) in enumerate([("Google Gemini", "google_key"), ("ElevenLabs", "eleven_key"), ("OpenAI (DALL-E)", "openai_key")]):
            ctk.CTkLabel(gf, text=lbl, font=BODY_FONT, text_color=TEXT).grid(row=r, column=0, sticky="w", pady=5)
            e = ctk.CTkEntry(gf, height=32, border_color=BORDER, fg_color=CARD2, text_color=TEXT, show="*")
            e.grid(row=r, column=1, sticky="ew", padx=10, pady=5)
            e.insert(0, cfg[key]); self.entries[key] = e

        # 3. ì˜µì…˜ ì¹´ë“œ
        f_opt = ctk.CTkFrame(self.main_scroll, fg_color=CARD, corner_radius=R, border_width=1, border_color=BORDER)
        f_opt.pack(fill="x", padx=20, pady=10)
        f_opt.columnconfigure(0, weight=1); f_opt.columnconfigure(1, weight=1)
        
        self.lang_var = ctk.StringVar(value="Korean")
        ctk.CTkOptionMenu(f_opt, variable=self.lang_var, values=LANG_OPTIONS, fg_color=CARD2, button_color=NEON, text_color=TEXT).grid(row=0, column=0, padx=10, pady=10, sticky="ew")
        
        self.voice_var = ctk.StringVar(value=list(VOICE_OPTIONS.keys())[0])
        ctk.CTkOptionMenu(f_opt, variable=self.voice_var, values=list(VOICE_OPTIONS.keys()), fg_color=CARD2, button_color=NEON, text_color=TEXT).grid(row=0, column=1, padx=10, pady=10, sticky="ew")
        
        self.color_var = ctk.StringVar(value=list(COLOR_OPTIONS.keys())[0])
        ctk.CTkOptionMenu(f_opt, variable=self.color_var, values=list(COLOR_OPTIONS.keys()), fg_color=CARD2, button_color=NEON, text_color=TEXT).grid(row=1, column=0, padx=10, pady=10, sticky="ew")
        
        self.hook_var = ctk.BooleanVar(value=True)
        ctk.CTkCheckBox(f_opt, text="í›„í‚¹ íƒ€ì´í‹€(3ì´ˆ) ìƒì„±", variable=self.hook_var, font=BODY_FONT, text_color=TEXT, fg_color=NEON).grid(row=1, column=1, padx=10, pady=10, sticky="w")

        # 4. ìƒì„± ì¹´ë“œ
        f_run = ctk.CTkFrame(self.main_scroll, fg_color=CARD, corner_radius=R, border_width=1, border_color=BORDER)
        f_run.pack(fill="x", padx=20, pady=10)
        
        self.entry_topic = ctk.CTkEntry(f_run, placeholder_text="ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë§›ì§‘ ë² ìŠ¤íŠ¸ 5)", height=40, font=BODY_FONT, fg_color=CARD2, border_color=BORDER, text_color=TEXT)
        self.entry_topic.pack(fill="x", padx=15, pady=15)
        
        btn_box = ctk.CTkFrame(f_run, fg_color="transparent")
        btn_box.pack(fill="x", padx=15, pady=(0, 10))
        self.btn_bgm = ctk.CTkButton(btn_box, text="BGM ì„ íƒ", font=BODY_FONT, fg_color=CARD2, hover_color=BORDER, text_color=TEXT, height=40, corner_radius=R, command=self.select_bgm)
        self.btn_bgm.pack(side="left", fill="x", expand=True, padx=(0, 5))
        self.btn_gen = ctk.CTkButton(btn_box, text="1. ê¸°íšì•ˆ ìƒì„±", font=FONT_BOLD, height=40, fg_color=NEON, hover_color="#00B8D4", text_color="black", corner_radius=R, command=self.run_gen)
        self.btn_gen.pack(side="left", fill="x", expand=True, padx=(5, 0))

        self.txt_script = ctk.CTkTextbox(f_run, height=100, fg_color=CARD2, border_color=BORDER, border_width=1, text_color=TEXT)
        self.txt_script.pack(fill="x", padx=15, pady=10)
        
        f_hk = ctk.CTkFrame(f_run, fg_color="transparent"); f_hk.pack(fill="x", padx=15)
        ctk.CTkLabel(f_hk, text="í›„í‚¹ ë¬¸êµ¬:", font=BODY_FONT, text_color=NEON).pack(side="left")
        self.entry_hook = ctk.CTkEntry(f_hk, height=32, fg_color=CARD2, border_color=BORDER, text_color=TEXT); self.entry_hook.pack(side="right", fill="x", expand=True, padx=(10,0))
        
        self.btn_render = ctk.CTkButton(f_run, text="2. ì˜ìƒ ìƒì„± ì‹œì‘", font=FONT_BOLD, height=50, fg_color=SUCCESS, hover_color="#25A76F", text_color="black", corner_radius=R, state="disabled", command=self.run_render)
        self.btn_render.pack(fill="x", padx=15, pady=15)
        
        # í‘¸í„°
        ctk.CTkLabel(self.main_scroll, text="Created by DuDu", font=SMALL_FONT, text_color=MUTED).pack(anchor="e", padx=20, pady=10)

    def select_bgm(self):
        f = filedialog.askopenfilename(filetypes=[("Audio","*.mp3")]); 
        if f: self.selected_bgm=f; self.btn_bgm.configure(text=f"âœ… {os.path.basename(f)}", fg_color="#2CC985", text_color="black")

    def run_gen(self):
        t = self.entry_topic.get(); k = self.entries["google_key"].get(); l = self.lang_var.get()
        if not t or not k: return messagebox.showwarning("!", "ì •ë³´ ë¶€ì¡±")
        self.btn_gen.configure(state="disabled", text="ìƒì„± ì¤‘...")
        threading.Thread(target=self.th_gen, args=(k, t, l), daemon=True).start()

    def th_gen(self, k, t, l):
        try:
            print("-" * 30)
            print(f"ğŸš€ ê¸°íšì•ˆ ìƒì„± ì‹œì‘: {t}")
            hook, script, prompts, metadata = generate_viral_content(k, t, l)
            self.gen_data["prompts"] = prompts
            self.gen_data["metadata"] = metadata
            
            self.txt_script.delete("1.0", "end"); self.txt_script.insert("1.0", script)
            self.entry_hook.delete(0, "end"); self.entry_hook.insert(0, hook)
            
            print("âœ… ê¸°íšì•ˆ ìƒì„± ì™„ë£Œ.")
            messagebox.showinfo("ì™„ë£Œ", "ê¸°íšì•ˆì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."); self.btn_render.configure(state="normal")
        except Exception as e: print(f"âŒ ì—ëŸ¬: {e}"); messagebox.showerror("Err", str(e))
        finally: self.btn_gen.configure(state="normal", text="1. ê¸°íšì•ˆ ìƒì„±")

    def run_render(self):
        scr = self.txt_script.get("1.0", "end").strip(); hook = self.entry_hook.get()
        if not scr: return
        
        ks = {k: v.get() for k, v in self.entries.items()}
        save_config(ks["openai_key"], ks["eleven_key"], ks["google_key"])
        
        vid = VOICE_OPTIONS[self.voice_var.get()]; clr = COLOR_OPTIONS[self.color_var.get()]; use_hk = self.hook_var.get()
        
        self.btn_render.configure(state="disabled", text="ì‘ì—… ì¤‘...", fg_color="#FF4444")
        threading.Thread(target=self.th_render, args=(ks, scr, hook, vid, clr, use_hk), daemon=True).start()

    def th_render(self, ks, scr, hook, vid, clr, use_hk):
        # ğŸ”¥ ì§„í–‰ë¥  ì‹œë®¬ë ˆì´ì…˜ìš© í”Œë˜ê·¸
        self.render_done = False
        
        try:
            print("-" * 30)
            print("ğŸ¬ ì˜ìƒ ë Œë”ë§ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
            
            # ====== 1ë‹¨ê³„: ìŒì„± ìƒì„± (0-15%) ======
            self.btn_render.configure(text="â— ìŒì„± ìƒì„± ì¤‘... 5%")
            vp = "temp_voice.mp3"
            if not generate_voice(ks["eleven_key"], scr, vp, vid): raise Exception("TTS ì‹¤íŒ¨")
            self.btn_render.configure(text="â— ìŒì„± ì™„ë£Œ! 15%")
            
            # ====== 2ë‹¨ê³„: ì´ë¯¸ì§€ ìƒì„± (15-45%) ======
            self.btn_render.configure(text="â— ì´ë¯¸ì§€ ìƒì„± ì¤‘... 20%")
            imgs = generate_images(ks["openai_key"], self.gen_data.get("prompts", []))
            self.btn_render.configure(text="â— ì´ë¯¸ì§€ ì™„ë£Œ! 45%")
            
            # ====== 3ë‹¨ê³„: ë Œë”ë§ (45-95%) - ì• ë‹ˆë©”ì´ì…˜ í‘œì‹œ ======
            self.btn_render.configure(text="â— ì˜ìƒ ë Œë”ë§ ì¤‘... 50%")
            
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì§„í–‰ë¥  ì• ë‹ˆë©”ì´ì…˜ (50% â†’ 95% â†’ ë°˜ë³µ)
            def simulate_progress():
                dots = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
                pct = 50
                idx = 0
                while not self.render_done:
                    # 50% â†’ 94% ê¹Œì§€ ì²œì²œíˆ ì¦ê°€
                    if pct < 94:
                        pct += 1
                    # 94%ì—ì„œ ì• ë‹ˆë©”ì´ì…˜ ê³„ì†
                    spinner = dots[idx % len(dots)]
                    self.btn_render.configure(text=f"{spinner} ë Œë”ë§ ì¤‘... {pct}%")
                    idx += 1
                    time.sleep(2.0 if pct < 90 else 0.3)  # 90% ì´í›„ëŠ” ë¹ ë¥´ê²Œ íšŒì „
            
            sim_thread = threading.Thread(target=simulate_progress, daemon=True)
            sim_thread.start()
            
            # ì‹¤ì œ ë Œë”ë§ (blocking)
            out_vid = f"Final_V30_{datetime.now().strftime('%H%M%S')}.mp4"
            make_video(vp, self.selected_bgm, imgs, scr, hook, out_vid, clr, use_hk)
            
            # ë Œë”ë§ ì™„ë£Œ - ì‹œë®¬ë ˆì´ì…˜ ì¤‘ì§€
            self.render_done = True
            self.btn_render.configure(text="â— ë§ˆë¬´ë¦¬ ì¤‘... 95%")
            
            # ====== 4ë‹¨ê³„: ì •ë¦¬ (95-100%) ======
            if "metadata" in self.gen_data:
                out_txt = out_vid.replace(".mp4", "_Upload_Info.txt")
                with open(out_txt, "w", encoding="utf-8") as f:
                    f.write(f"ğŸ“º ì£¼ì œ: {self.entry_topic.get()}\n" + "="*30 + "\n")
                    f.write(self.gen_data["metadata"])
                    f.write("\n" + "="*30 + "\nMade with KnowledgeMaker V30")
                    print(f"ğŸ“„ ì—…ë¡œë“œ ì •ë³´ ì €ì¥ë¨: {out_txt}")

            if os.path.exists(vp): os.remove(vp)
            shutil.rmtree("images_ultra", ignore_errors=True)
            
            self.btn_render.configure(text="âœ… ì™„ë£Œ! 100%")
            print(f"âœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ! íŒŒì¼: {out_vid}")
            messagebox.showinfo("ì„±ê³µ", f"ì˜ìƒ ìƒì„± ì™„ë£Œ!\nğŸ“ {out_vid}")
            
        except Exception as e: 
            self.render_done = True  # ì‹œë®¬ë ˆì´ì…˜ ì¤‘ì§€
            print(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            messagebox.showerror("Err", str(e))
        finally: 
            self.render_done = True
            self.btn_render.configure(state="normal", text="2. ì˜ìƒ ìƒì„± ì‹œì‘", fg_color="#2CC985")

if __name__ == "__main__":
    app = KnowledgeMakerUltra()
    app.mainloop()
